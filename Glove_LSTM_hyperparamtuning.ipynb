{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"Glove_LSTM_hyperparamtuning.ipynb","provenance":[{"file_id":"1q5VeSpq_9jwJIx2_5jf0VehXYNO1xDv7","timestamp":1591093397093},{"file_id":"1D-OljKnp3xdclEbvGqj6FuY8XO_TTglj","timestamp":1584020332575}],"collapsed_sections":[]},"accelerator":"TPU"},"cells":[{"cell_type":"code","metadata":{"id":"MW3L1Loy4Z2Y","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1593021770858,"user_tz":-120,"elapsed":1497,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"387d6eb3-e2fa-461d-ebdc-df38feaf299a"},"source":["# %matplotlib inline\n","# import matplotlib.pyplot as plt\n","# import tensorflow as tf\n","import numpy as np\n","import pandas as pd\n","\n","from tensorflow.keras import backend as k\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, GRU, Embedding, Dropout, LSTM, Bidirectional\n","from tensorflow.keras.optimizers import Adam\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.callbacks import EarlyStopping\n","from tensorflow.keras.models import model_from_json\n","\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","nltk.download('punkt')\n","\n","import pickle\n","\n","# print(tf.__version__)\n","# print(tf.keras.__version__)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sf5m98zfxwDH","colab_type":"text"},"source":["# This code is partly based on a tutorial which can be found here:\n","# https://realpython.com/python-keras-text-classification/#what-is-a-word-embedding"]},{"cell_type":"code","metadata":{"id":"nnVjGsno7q-d","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":816},"executionInfo":{"status":"ok","timestamp":1593021775759,"user_tz":-120,"elapsed":6354,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"6d7d0ed7-ff9d-4567-fda7-adf097700874"},"source":["#Packages to import (regular expressions and pandas)\n","\n","import re \n","import pandas as pd \n","\n","from pathlib import Path\n","import gzip\n","import json\n","\n","# Code to read csv file into Colaboratory:\n","!pip install -U -q PyDrive\n","from pydrive.auth import GoogleAuth\n","from pydrive.drive import GoogleDrive\n","from google.colab import auth\n","from oauth2client.client import GoogleCredentials\n","\n","#Mount google colab to google drive so it can access files\n","from google.colab import drive\n","drive.mount('/content/drive')\n","\n","#The huge gzipped JSON files ('NL_jobs.15.jsonl.gz') are located in this folder\n","cwd = '/content/drive/My Drive/Werkinzicht_Clyde/Notebooks/Experiments'\n","\n","#Print the content of the folder\n","!ls '/content/drive/My Drive/Werkinzicht_Clyde/Notebooks/Experiments'\n","\n","# set current working directory, This folder should only contain the huge json files.\n","%cd '/content/drive/My Drive/Werkinzicht_Clyde/Notebooks/Experiments'\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","'Baseline Model (BOW Log. regression).ipynb'\n"," BERT_alt_deploy.ipynb\n","'BERT_Jads_Nikita- Clyde edit - hpartuning.ipynb'\n"," BOW_LSTM.ipynb\n","'Copy of Copy of BERT_alt _ hyperparamtuning.ipynb'\n"," CORPUSNL_jobs.15.jsonl.gz_JSON_splitted.tsv_1.tsv\n"," Cow\n"," COW_LSTM_hyperparamtuning.ipynb\n"," dev.gsheet\n"," dev.tsv\n"," df3_updated_clean.txt\n"," df3_updated.txt\n"," df4_updated_clean.txt\n"," df4_updated.txt\n"," Exp23_RNDSCV.csv\n"," Exp25_RNDSCV.csv\n"," Exp26_RNDSCV.csv\n"," Exp27_RNDSCV.csv\n"," Exp28_RNDSCV.csv\n"," Exp29_RNDSCV.csv\n"," Exp30_RNDSCV.csv\n"," Exp31_RNDSCV.csv\n"," Exp32_RNDSCV.csv\n"," Exp33_RNDSCV.csv\n"," Exp34_RNDSCV.csv\n"," Exp35_RNDSCV.csv\n"," Exp36_RNDSCV.csv\n"," fastText-0.1.0\n"," glove.6B\n"," glove.6B.zip\n"," glove.model\n"," model.h5\n"," model.json\n"," NL_Embedding\n"," NL_jobs.15.jsonl.gz_JSON_splitted.tsv\n"," temp\n"," tokenizer.pickle\n"," train.gsheet\n"," train.tsv\n"," v0.1.0.zip\n"," v0.1.0.zip.1\n"," v0.1.0.zip.2\n"," Word2Vec_LSTM_hyperparamtuning.ipynb\n"," Word_Embedding_LSTM_hyperparamtuning.ipynb\n"," Word_Embedding_LSTM.ipynb\n","/content/drive/My Drive/Werkinzicht_Clyde/Notebooks/Experiments\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"q176l_o_4Z2e","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1593021775761,"user_tz":-120,"elapsed":6329,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"bcc314d1-1fe0-4f98-a2ed-4888bdee9d17"},"source":["TRAIN_FILE = \"train.tsv\"\n","DEV_FILE = \"dev.tsv\"\n","\n","CORPUS_FILE = \"CORPUSNL_jobs.15.jsonl.gz_JSON_splitted.tsv_1.tsv\"\n","print(\"TRAIN FILE: \\t\\t{}\\nDEVELOPMENT FILE: \\t{}\".format(TRAIN_FILE, DEV_FILE))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["TRAIN FILE: \t\ttrain.tsv\n","DEVELOPMENT FILE: \tdev.tsv\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"otEAcrALHhZV","colab_type":"code","colab":{}},"source":["# Load the data\n","corpus_full = pd.read_csv(CORPUS_FILE, sep = \"\\t\")\n","\n","# ts = arr.tostring()\n","# Tirm the data to only one we need\n","corpus_train = np.array(corpus_full[\"#1 String\"])\n","\n","corpus_train2 = corpus_train.astype('str') \n","\n","# Seperate our data for training and testing\n","# train_text = (corpus_full[\"#1 String\"])\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HnmvjHrjIP1Z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593021780834,"user_tz":-120,"elapsed":11330,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"605ca8c3-86f4-4603-ab02-d9ab82cc27d1"},"source":["corpus_train2[0:100]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array(['Functiegroep', 'Techniek', 'Functie', 'werkvoorbereider',\n","       'Branche', 'Energie/Gas/Water', 'Telecom', 'Dienstverband', 'Uren',\n","       '36 - 40 uur per week', 'Opleidingsniveau', 'MBO',\n","       'Carrièreniveau', 'Starter', 'Salaris',\n","       '€ 2000 - 2500 bruto per maand', 'Adres', 'Middelweg 2',\n","       '5253CA Nieuwkuijk', 'Contactgegevens', 'Bas de Bruin',\n","       'Tel.: 0615951702', 'bdebruin@thepeoplegroup.nl',\n","       'Vacaturecode: 63559834 Meld Misbruik',\n","       'Waan je als tester in de wereld van CSI', 'Testing Professionals',\n","       '2500-3500', 'HBO', '40 uur', '40 uur', 'HBO', '2500-3500',\n","       'Vandaag', '2x bekeken', 'Functieomschrijving',\n","       'Je krijgt de kans om te werken in Team Software Engineering, bestaande uit 12 software ontwikkelaars en een aantal software testers.',\n","       \"De testing kennis zit nu nog voornamelijk bij een aantal externe testers die worden ingehuurd, maar het doel is om deze kennis ook intern meer te borgen, middels het verder uitbouwen van 'eigen' software testers.\",\n","       'Het team ontwikkelt en werkt aan een grote verscheidenheid aan software producten, waardoor het als tester steeds uitdagend blijft en je niet telkens aan dezelfde applicatie zit te testen.',\n","       'Als test engineer ontwikkel je tests om de kwaliteit van de applicaties te bewaken, waarbij je zelfstandig testframeworks toepast en waar nodig zorgt voor aanpassingen en uitbreidingen.',\n","       \"Enige kennis van test automation is dus een grote pre, maar er wordt niet 'geautomatiseerd om het automatiseren'.\",\n","       'Voor het testen van applicaties maken ze nu o.a. gebruik van JUnit, JBehave en Mockito, maar deze set kan uiteraard verder worden uitgebreid.',\n","       'Testing maakt deel uit van een continuous delivery proces dat is opgezet met Bamboo.',\n","       'Het team kan vanuit Jira met een druk op de knop applicaties testen en verder uitrollen.',\n","       'Als test engineer krijg je dus de kans om dit proces verder te verbeteren en bij te dragen aan de kwaliteit van software voor opsporing en bewijsvoering.',\n","       \"Denk hierbij aan software voor het detecteren van afwijkingen in digitale foto's en te zoeken in een zoekmachine van in beslag genomen digitaal materiaal.\",\n","       'Met jouw werk draag je bij aan waarheidsvinding en draag je op deze manier jouw',\n","       'steentje bij aan de maatschappij.',\n","       'Binnen het team krijg je de ruimte om nieuwe ideeën in te brengen om software voor opsporing en bewijsvorming te verbeteren.',\n","       'Het team helpt en versterkt elkaar hierbij waar nodig, bijvoorbeeld met pair programming en code reviews.',\n","       'Het is een team van relatief jonge professionals waarbinnen een fijne informele, open sfeer hangt.',\n","       'Er wordt vaak samen geluncht en daarna even een rondje gelopen in de omgeving en vanuit zowel de afdeling als het team worden ook leuke groepsuitjes en - activiteiten georganiseerd.',\n","       'Functie-eisen',\n","       'Je hebt minimaal een afgeronde HBO opleiding, bij voorkeur richting Informatica of een andere bèta studie.',\n","       'Je hebt minimaal 2 jaar ervaring met software testing en test frameworks',\n","       'Affiniteit met programmeren, liefst in Java',\n","       'Je kunt goed in teamverband werken en bent proactief.',\n","       'Projectmatig werken aan verschillende producten spreekt je aan.',\n","       'Arbeidsvoorwaarden', 'Salaris van 2.650,- tot 4.050,- p/m',\n","       '36-urige werkweek (flexibel invulling aan te geven)',\n","       'Vaste 13de maand',\n","       'Sterke focus op persoonlijke groei en loopbaanontwikkeling',\n","       'Maximaal 55% betaald ouderschapsverlof (onder voorwaarden)',\n","       'Aantal individuele keuzemogelijkheden bij het samenstellen van je arbeidsvoorwaardenpakket',\n","       'Sollicitatieprocedure', 'Interesse in deze vacature?',\n","       'Solliciteer via de knop en stuur ons jouw meest recente CV.',\n","       'Wij nemen dan zsm contact met je op.',\n","       'Vragen of opmerkingen over de vacature?', 'Mail naar',\n","       'Klik op de solliciteer-button om te solliciteren -, of bel naar 020 8203 755.',\n","       'Testing Professionals', 'Waarom bij ons werken?',\n","       'Ben jij een Testspecialist en heb je interesse in onze vacature?',\n","       'Dan horen we graag van je!',\n","       'Ben je benieuwd naar al onze andere Test vacatures kun je ook kijken op onze website: www.testing-professionals.nl.',\n","       'Testing Professionals is een gespecialiseerd Werving- en Selectie bureau dat zich volledig focust op recruitment van Testing specialisten.',\n","       \"Door deze sterke focus zijn wij continu op de hoogte van de nieuwste ontwikkelingen in de markt en weten zo nuance aan te brengen in de standaard vacature profielen voor Testing specialisten. 'De juiste match maken' is een veelgehoorde term binnen recruitment.\",\n","       'Voor ons betekent dit dat wij als recruiter erop moeten toezien dat wij niet de tijd van onze klant én kandidaat verdoen.',\n","       'Een goede kwalificatie en goede voorbereiding zijn daarom essentieel voor een goed verloop van elk sollicitatie proces.',\n","       'Met onze toewijding, inzet én specialisme in Testing zijn wij daarom zowel voor klant als kandidaat de juiste partij als Testing de inzet is!',\n","       'Wij zijn Testing Professionals.',\n","       'Een werving- & selectiebureau gespecialiseerd in de werving en selectie van Testspecialisten.',\n","       'Ons team van Recruitment Consultants werken dagelijks samen met zowel opdrachtgevers als kandidaten binnen de Nederlandse markt om werkgevers en werknemers bij elkaar te brengen.',\n","       'Soort organisatie', 'Werving & selectie / uitzendbureau',\n","       'Branche', 'Automatisering/IT', 'Locaties', 'Aantal medewerkers',\n","       '1-10', 'Internationaal actief', 'Jaar van oprichting', '2010',\n","       'Omzet', '500.000- 1.000.000', 'Bedrijfsinfo', 'Website',\n","       'Ga naar website', 'Locaties'], dtype='<U1584')"]},"metadata":{"tags":[]},"execution_count":48}]},{"cell_type":"code","metadata":{"id":"bvHjyC5o4Z2l","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1593021780836,"user_tz":-120,"elapsed":11283,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"5251e165-5146-48c8-c187-d1d112ad89f0"},"source":["# Load the data\n","test_full = pd.read_csv(TRAIN_FILE, sep = \"\\t\")\n","dev_full = pd.read_csv(DEV_FILE, sep = \"\\t\")\n","\n","# Tirm the data to only one we need\n","test_trim = test_full[[\"Quality\", \"#1 String\"]]\n","dev_trim = dev_full[[\"Quality\", \"#1 String\"]]\n","\n","# Seperate our data for training and testing\n","train_text = np.array(test_full[\"#1 String\"])\n","train_target = np.array(test_full[\"Quality\"])\n","\n","test_text = np.array(dev_full[\"#1 String\"])\n","test_target = np.array(dev_full[\"Quality\"])\n","\n","# Check our training and testing sets\n","print(\"Train-set size: \", len(train_text))\n","print(\"Test-set size:  \", len(test_text))\n","\n","# Stack text for tokenization\n","data_text = np.hstack((train_text, test_text))\n","print(\"Shape of the stacked text: {}\".format(data_text.shape))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Train-set size:  2240\n","Test-set size:   720\n","Shape of the stacked text: (2960,)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bbhITV8B4Z2w","colab_type":"code","colab":{}},"source":["# Get stop words (or most commoon ones basically) for the dutch language\n","stop_words = set(stopwords.words('dutch'))\n","\n","# Get the tokinized pattern of all sentences\n","word_tokens = []\n","for sentence in data_text:\n","    word_tokens.append(nltk.word_tokenize(sentence))\n","\n","# Initiate a new collector\n","filtered_sentence = []\n","for entry in word_tokens:\n","    filtered_sentence.append([w for w in entry if not w in stop_words and w.isalpha()])\n","filtered_sentence = np.array(filtered_sentence)\n","\n","# Implement the top level tokinizer, we will go for 10K words\n","num_words = 10000\n","tokenizer = Tokenizer(num_words=num_words)\n","tokenizer.fit_on_texts(filtered_sentence)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-VBDiFAm4Z21","colab_type":"code","colab":{}},"source":["# tokenizer.word_index # If we need to check it"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fwqp-UPr4Z26","colab_type":"code","colab":{}},"source":["# Save the tokinizer for re-usability with the new data\n","import pickle\n","with open('tokenizer.pickle', 'wb') as handle:\n","    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vpzkYm3y4Z2-","colab_type":"code","colab":{}},"source":["# loading\n","with open('tokenizer.pickle', 'rb') as handle:\n","    tokenizer = pickle.load(handle)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xhsCkjh74Z3F","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":255},"executionInfo":{"status":"ok","timestamp":1593021781384,"user_tz":-120,"elapsed":11688,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"a84e84fc-999a-4ea8-d314-6962540c55c9"},"source":["x_train_tokens = tokenizer.texts_to_sequences(train_text)\n","x_test_tokens = tokenizer.texts_to_sequences(test_text)\n","\n","vocab_size = len(tokenizer.word_index) + 1  \n","\n","# Example of conversions\n","print(\"Conversion Examples:\")\n","print(x_train_tokens[50])\n","print(train_text[50])\n","print(\"---------------------------------\")\n","print(x_train_tokens[100])\n","print(train_text[100])\n","print(\"---------------------------------\")\n","\n","# Padding the data if needed\n","num_tokens = [len(tokens) for tokens in x_train_tokens + x_test_tokens]\n","num_tokens = np.array(num_tokens)\n","print(\"Average Number of Tokens per sentence: \", np.round(np.mean(num_tokens), 4))\n","print(\"Maxmimum Number of Tokens per sentence: \", np.max(num_tokens))\n","print(\"Minimum Number of Tokens per sentence: \", np.min(num_tokens))\n","\n","# The max number of tokens we will allow is set to the average plus 2 standard deviations.\n","max_tokens = np.mean(num_tokens) + 2 * np.std(num_tokens)\n","max_tokens = int(max_tokens)\n","print(\"Maximum amount of tokens to hold: \", max_tokens)\n","\n","# This covers almost 96% of the data\n","print(\"How much data does the padding include fully: {}\".format(np.sum(num_tokens < max_tokens) / len(num_tokens)))\n","\n","# Initiate the condition for padding\n","pad = 'pre'\n","\n","# Applying padding to the training data\n","x_train_pad = pad_sequences(x_train_tokens,\n","                            maxlen=max_tokens,\n","                            padding=pad,\n","                            truncating=pad)\n","\n","# Applying padding to the development data\n","\n","x_test_pad = pad_sequences(x_test_tokens, \n","                           maxlen=max_tokens, \n","                           padding=pad, \n","                           truncating=pad)\n","\n","# Verify that all of the padding is done correctly\n","print(\"Shape of the padded testing data: \\t\", x_train_pad.shape)\n","print(\"Shape of the padded development data: \\t\", x_test_pad.shape)\n","# Seems correct"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Conversion Examples:\n","[233, 2386, 245, 2387]\n","Utrecht, Drenthe en Flevoland.\n","---------------------------------\n","[13, 152, 614, 298, 1211, 2416, 298, 2417, 462, 237, 298, 2418, 835, 115, 823, 2419, 710]\n","het, met behulp van ons calculatieprogramma BV6 van TSD uit Zwolle, uitwerken van prijsaanvragen tot een correcte werkomschrijvende offerte\n","---------------------------------\n","Average Number of Tokens per sentence:  12.7966\n","Maxmimum Number of Tokens per sentence:  58\n","Minimum Number of Tokens per sentence:  0\n","Maximum amount of tokens to hold:  29\n","How much data does the padding include fully: 0.9618243243243243\n","Shape of the padded testing data: \t (2240, 29)\n","Shape of the padded development data: \t (720, 29)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zuYgvfPaPAZF","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593021781385,"user_tz":-120,"elapsed":11610,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"abfdc5b1-45e8-4be0-c359-7229ef7bbb3d"},"source":["print(\"Shape of the padded testing data: \\t\", corpus_train_pad.shape)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Shape of the padded testing data: \t (496016, 18)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8odkIrVfPdHM","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":221},"executionInfo":{"status":"ok","timestamp":1593021786651,"user_tz":-120,"elapsed":16763,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"4c661ad1-06b2-4686-b7b3-e51dacde486d"},"source":["# corpus_train2[0:50]\n","\n","\n","list_train_text = corpus_train2.tolist()\n","print(type(list_train_text))\n","print(list_train_text[0:10])\n","\n","s = ['hello everyone', 'how are you', 'i am fine']\n","word_list = [c.split() for c in list_train_text]\n","print(word_list) \n","\n","print(word_list[0:10])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","['Functiegroep', 'Techniek', 'Functie', 'werkvoorbereider', 'Branche', 'Energie/Gas/Water', 'Telecom', 'Dienstverband', 'Uren', '36 - 40 uur per week']\n"],"name":"stdout"},{"output_type":"stream","text":["IOPub data rate exceeded.\n","The notebook server will temporarily stop sending output\n","to the client in order to avoid crashing it.\n","To change this limit, set the config variable\n","`--NotebookApp.iopub_data_rate_limit`.\n","\n","Current values:\n","NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n","NotebookApp.rate_limit_window=3.0 (secs)\n","\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"qMmVkOyQlPQB","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":544},"executionInfo":{"status":"ok","timestamp":1593021853027,"user_tz":-120,"elapsed":83112,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"5e8c440a-7ee6-453d-d06c-fb10bdaab4f0"},"source":["#importing the glove library\n","from glove import Corpus, Glove\n","# creating a corpus object\n","corpus = Corpus() \n","#training the corpus to generate the co occurence matrix which is used in GloVe\n","\n","\n","corpus.fit(word_list, window=10)\n","#creating a Glove object which will use the matrix created in the above lines to create embeddings\n","#We can set the learning rate as it uses Gradient Descent and number of components\n","glove = Glove(no_components=5, learning_rate=0.05)\n"," \n","glove.fit(corpus.matrix, epochs=30, no_threads=4, verbose=True)\n","glove.add_dictionary(corpus.dictionary)\n","glove.save('glove.model')\n","glove.add_dictionary(corpus.dictionary)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Performing 30 training epochs with 4 threads\n","Epoch 0\n","Epoch 1\n","Epoch 2\n","Epoch 3\n","Epoch 4\n","Epoch 5\n","Epoch 6\n","Epoch 7\n","Epoch 8\n","Epoch 9\n","Epoch 10\n","Epoch 11\n","Epoch 12\n","Epoch 13\n","Epoch 14\n","Epoch 15\n","Epoch 16\n","Epoch 17\n","Epoch 18\n","Epoch 19\n","Epoch 20\n","Epoch 21\n","Epoch 22\n","Epoch 23\n","Epoch 24\n","Epoch 25\n","Epoch 26\n","Epoch 27\n","Epoch 28\n","Epoch 29\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-uip7btGPTGG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1593021853031,"user_tz":-120,"elapsed":83090,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"0a3438e6-4ae2-4ec5-8e71-f69a63d1e395"},"source":["print(glove.word_vectors[glove.dictionary['Maximaal']])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[ 0.06591277  0.00852954 -0.05075319 -0.26351811  0.03398965]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"YEHyPsAJeRsF","colab_type":"code","colab":{}},"source":["def create_model(lstm1, lstm2, dense1):\n","    #Creating the network\n","    # embedding_size = 256\n","    # num_words = num_words # We chose this value earlier (10,000)\n","    # max_tokens = max_tokens # This values is also chosen from before (30)\n","\n","    # For reproducability setting a seed\n","    seed = 42\n","    # np.random.seed(seed)\n","\n","    model = Sequential()\n","    model.add(Embedding(input_dim=194178,\n","                        output_dim=5,\n","                        weights = [glove.word_vectors], \n","                        trainable = True,\n","                        input_length=29,\n","                        name='layer_embedding'))\n","    model.add(Bidirectional(LSTM(units = lstm1, return_sequences=True, name = \"BiLSTM_1\")))\n","    model.add(Dropout(0.5, noise_shape=None, seed=seed))\n","    model.add(Bidirectional(LSTM(units = lstm2, return_sequences=False, name = \"BiLSTM_2\")))\n","    model.add(Dropout(0.5, noise_shape=None, seed=seed))\n","    model.add(Dense(dense1, activation='relu', name = \"Intermediate_1\"))\n","    Dropout(rate = 0.5, noise_shape=None, seed=seed)\n","    # model.add(Dense(16, activation='relu', name = \"Intermediate_2\"))\n","    model.add(Dense(1, activation='sigmoid', name = \"Final_Output\"))\n","    optimizer = Adam(lr = 1e-3)\n","    model.compile(loss='binary_crossentropy',\n","                  optimizer=optimizer,\n","                  metrics=['acc'])\n","    # model.summary()\n","\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhNAMsIyCokj","colab_type":"code","colab":{}},"source":["param_grid = dict(lstm1=[4,8,16, 32],\n","                  lstm2=[4, 8,16, 32],\n","                  dense1=[4, 8,16, 32]         \n","                  # vocab_size=[5000], \n","                  # embedding_dim=[50, 30, 80],\n","                )\n","\n","# param_grid = dict(lstm1=[16, 32],\n","#                   lstm2=[16, 32],\n","#                   dense1=[16, 32],          \n","#                   vocab_size=[5000], \n","#                   embedding_dim=[50],\n","#                   maxlen=[29],\n","#                    random_state=1, refit=True,\n","#                    return_train_score=True\n","#                   )\n","\n","\n","# param_grid = dict(batch_size_param=[16, 32, 64, 128],\n","#                   lr_param=[1e-3, 5e-5, 3e-5, 2e-5],          \n","#                   vocab_size=[5000], \n","#                   embedding_dim=[50],\n","#                   maxlen=[29],       \n","#                    )\n","\n","\n","# param_grid = dict(num_filters=[32, 64, 128],\n","#                   kernel_size=[3, 5, 7],\n","#                   vocab_size=[vocab_size],\n","#                   embedding_dim=[embedding_dim],\n","#                   maxlen=[maxlen])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iZTR9OshFgCz","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":289},"executionInfo":{"status":"ok","timestamp":1593023714086,"user_tz":-120,"elapsed":1561978,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"b776884c-c842-4d2f-a60d-d87b376ec67c"},"source":["from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.model_selection import RandomizedSearchCV\n","\n","\n","output_file = 'data/output.txt'\n","\n","from sklearn.ensemble import GradientBoostingRegressor\n","from sklearn.metrics import fbeta_score, make_scorer\n","\n","\n","epochs = 15\n","cv_folds = 4\n","n_iter = 20\n","batch_size = 128\n","\n","model = KerasClassifier(build_fn=create_model,\n","                        epochs=epochs, batch_size= batch_size,\n","                        verbose=False\n","                       )\n","\n","grid = RandomizedSearchCV(estimator=model, param_distributions=param_grid,\n","                          cv= cv_folds, verbose=1, n_iter= n_iter,\n","                          # scoring= score,\n","                          return_train_score = True,\n","                          n_jobs = -1,\n","                          refit = True\n","                          )\n","\n","\n","\n","from tensorflow.keras.callbacks import EarlyStopping\n","\n","# Define early stopping\n","early_stopping = EarlyStopping(monitor='loss', patience=5)\n","\n","\n","grid_result = grid.fit(x_train_pad, train_target, callbacks=[early_stopping])\n","\n","# Evaluate testing set\n","test_accuracy = grid.score(x_test_pad, test_target)\n","\n","print(grid_result.best_score_)\n","print(grid_result.best_params_)\n","# print(test_accuracy)\n","print(grid_result)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Fitting 4 folds for each of 20 candidates, totalling 80 fits\n"],"name":"stdout"},{"output_type":"stream","text":["[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n","/usr/local/lib/python3.6/dist-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n","  \"timeout or by a memory leak.\", UserWarning\n","[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 14.5min\n","[Parallel(n_jobs=-1)]: Done  80 out of  80 | elapsed: 25.7min finished\n"],"name":"stderr"},{"output_type":"stream","text":["0.7799107134342194\n","{'lstm2': 16, 'lstm1': 4, 'dense1': 32}\n","RandomizedSearchCV(cv=4, error_score=nan,\n","                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fc5d59db6a0>,\n","                   iid='deprecated', n_iter=20, n_jobs=-1,\n","                   param_distributions={'dense1': [4, 8, 16, 32],\n","                                        'lstm1': [4, 8, 16, 32],\n","                                        'lstm2': [4, 8, 16, 32]},\n","                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n","                   return_train_score=True, scoring=None, verbose=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-F9onQ_F06Td","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1593023714090,"user_tz":-120,"elapsed":1561961,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"bb5e9f65-0f00-4cfa-8d50-59764c901250"},"source":["df_end = pd.DataFrame(grid_result.cv_results_)\n","df_end\n","# df_end.to_csv('Exp36_RNDSCV.csv')"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>mean_fit_time</th>\n","      <th>std_fit_time</th>\n","      <th>mean_score_time</th>\n","      <th>std_score_time</th>\n","      <th>param_lstm2</th>\n","      <th>param_lstm1</th>\n","      <th>param_dense1</th>\n","      <th>params</th>\n","      <th>split0_test_score</th>\n","      <th>split1_test_score</th>\n","      <th>split2_test_score</th>\n","      <th>split3_test_score</th>\n","      <th>mean_test_score</th>\n","      <th>std_test_score</th>\n","      <th>rank_test_score</th>\n","      <th>split0_train_score</th>\n","      <th>split1_train_score</th>\n","      <th>split2_train_score</th>\n","      <th>split3_train_score</th>\n","      <th>mean_train_score</th>\n","      <th>std_train_score</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>35.715215</td>\n","      <td>0.280475</td>\n","      <td>2.916239</td>\n","      <td>0.291775</td>\n","      <td>4</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>{'lstm2': 4, 'lstm1': 32, 'dense1': 16}</td>\n","      <td>0.748214</td>\n","      <td>0.773214</td>\n","      <td>0.751786</td>\n","      <td>0.703571</td>\n","      <td>0.744196</td>\n","      <td>0.025329</td>\n","      <td>16</td>\n","      <td>0.905357</td>\n","      <td>0.869048</td>\n","      <td>0.845833</td>\n","      <td>0.867857</td>\n","      <td>0.872024</td>\n","      <td>0.021350</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>30.617582</td>\n","      <td>0.816938</td>\n","      <td>2.944659</td>\n","      <td>0.295722</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>{'lstm2': 8, 'lstm1': 16, 'dense1': 4}</td>\n","      <td>0.750000</td>\n","      <td>0.805357</td>\n","      <td>0.766071</td>\n","      <td>0.701786</td>\n","      <td>0.755804</td>\n","      <td>0.037123</td>\n","      <td>10</td>\n","      <td>0.888095</td>\n","      <td>0.867262</td>\n","      <td>0.886310</td>\n","      <td>0.888095</td>\n","      <td>0.882440</td>\n","      <td>0.008794</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>35.943490</td>\n","      <td>0.469996</td>\n","      <td>2.909779</td>\n","      <td>0.291271</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>8</td>\n","      <td>{'lstm2': 8, 'lstm1': 32, 'dense1': 8}</td>\n","      <td>0.732143</td>\n","      <td>0.796429</td>\n","      <td>0.748214</td>\n","      <td>0.733929</td>\n","      <td>0.752679</td>\n","      <td>0.026016</td>\n","      <td>11</td>\n","      <td>0.882738</td>\n","      <td>0.832143</td>\n","      <td>0.832738</td>\n","      <td>0.872024</td>\n","      <td>0.854911</td>\n","      <td>0.022788</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>28.740405</td>\n","      <td>1.097446</td>\n","      <td>2.958508</td>\n","      <td>0.257216</td>\n","      <td>8</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>{'lstm2': 8, 'lstm1': 8, 'dense1': 16}</td>\n","      <td>0.778571</td>\n","      <td>0.655357</td>\n","      <td>0.796429</td>\n","      <td>0.689286</td>\n","      <td>0.729911</td>\n","      <td>0.059163</td>\n","      <td>20</td>\n","      <td>0.919048</td>\n","      <td>0.782143</td>\n","      <td>0.870238</td>\n","      <td>0.841071</td>\n","      <td>0.853125</td>\n","      <td>0.049554</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>31.760548</td>\n","      <td>0.354100</td>\n","      <td>2.933289</td>\n","      <td>0.344224</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>{'lstm2': 8, 'lstm1': 16, 'dense1': 8}</td>\n","      <td>0.755357</td>\n","      <td>0.762500</td>\n","      <td>0.773214</td>\n","      <td>0.703571</td>\n","      <td>0.748661</td>\n","      <td>0.026797</td>\n","      <td>15</td>\n","      <td>0.910119</td>\n","      <td>0.838095</td>\n","      <td>0.838095</td>\n","      <td>0.885714</td>\n","      <td>0.868006</td>\n","      <td>0.031130</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>35.209018</td>\n","      <td>0.957863</td>\n","      <td>3.014147</td>\n","      <td>0.174357</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>{'lstm2': 32, 'lstm1': 16, 'dense1': 4}</td>\n","      <td>0.742857</td>\n","      <td>0.803571</td>\n","      <td>0.814286</td>\n","      <td>0.728571</td>\n","      <td>0.772321</td>\n","      <td>0.037148</td>\n","      <td>2</td>\n","      <td>0.875000</td>\n","      <td>0.907738</td>\n","      <td>0.878571</td>\n","      <td>0.919643</td>\n","      <td>0.895238</td>\n","      <td>0.018968</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>28.662930</td>\n","      <td>0.571588</td>\n","      <td>3.023258</td>\n","      <td>0.262464</td>\n","      <td>4</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>{'lstm2': 4, 'lstm1': 4, 'dense1': 8}</td>\n","      <td>0.732143</td>\n","      <td>0.792857</td>\n","      <td>0.703571</td>\n","      <td>0.701786</td>\n","      <td>0.732589</td>\n","      <td>0.036822</td>\n","      <td>19</td>\n","      <td>0.831548</td>\n","      <td>0.814881</td>\n","      <td>0.719048</td>\n","      <td>0.810714</td>\n","      <td>0.794048</td>\n","      <td>0.043997</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>28.467727</td>\n","      <td>0.742300</td>\n","      <td>2.804130</td>\n","      <td>0.376697</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>{'lstm2': 4, 'lstm1': 8, 'dense1': 32}</td>\n","      <td>0.691071</td>\n","      <td>0.775000</td>\n","      <td>0.810714</td>\n","      <td>0.732143</td>\n","      <td>0.752232</td>\n","      <td>0.044952</td>\n","      <td>12</td>\n","      <td>0.824405</td>\n","      <td>0.875595</td>\n","      <td>0.917857</td>\n","      <td>0.888690</td>\n","      <td>0.876637</td>\n","      <td>0.033814</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>31.745901</td>\n","      <td>0.539628</td>\n","      <td>3.289021</td>\n","      <td>0.447765</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>{'lstm2': 16, 'lstm1': 8, 'dense1': 16}</td>\n","      <td>0.741071</td>\n","      <td>0.780357</td>\n","      <td>0.705357</td>\n","      <td>0.733929</td>\n","      <td>0.740179</td>\n","      <td>0.026771</td>\n","      <td>18</td>\n","      <td>0.841071</td>\n","      <td>0.811905</td>\n","      <td>0.852381</td>\n","      <td>0.909524</td>\n","      <td>0.853720</td>\n","      <td>0.035441</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>32.825748</td>\n","      <td>1.294722</td>\n","      <td>3.136111</td>\n","      <td>0.326052</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>{'lstm2': 4, 'lstm1': 16, 'dense1': 8}</td>\n","      <td>0.739286</td>\n","      <td>0.816071</td>\n","      <td>0.798214</td>\n","      <td>0.717857</td>\n","      <td>0.767857</td>\n","      <td>0.040505</td>\n","      <td>4</td>\n","      <td>0.905357</td>\n","      <td>0.879762</td>\n","      <td>0.891071</td>\n","      <td>0.879167</td>\n","      <td>0.888839</td>\n","      <td>0.010651</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>33.350198</td>\n","      <td>0.293724</td>\n","      <td>3.257539</td>\n","      <td>0.340631</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>{'lstm2': 4, 'lstm1': 16, 'dense1': 16}</td>\n","      <td>0.755357</td>\n","      <td>0.792857</td>\n","      <td>0.744643</td>\n","      <td>0.716071</td>\n","      <td>0.752232</td>\n","      <td>0.027502</td>\n","      <td>12</td>\n","      <td>0.894643</td>\n","      <td>0.860714</td>\n","      <td>0.848810</td>\n","      <td>0.860119</td>\n","      <td>0.866071</td>\n","      <td>0.017164</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>30.854425</td>\n","      <td>1.467581</td>\n","      <td>2.790194</td>\n","      <td>0.334234</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>16</td>\n","      <td>{'lstm2': 16, 'lstm1': 4, 'dense1': 16}</td>\n","      <td>0.733929</td>\n","      <td>0.800000</td>\n","      <td>0.801786</td>\n","      <td>0.707143</td>\n","      <td>0.760714</td>\n","      <td>0.041284</td>\n","      <td>9</td>\n","      <td>0.838095</td>\n","      <td>0.870833</td>\n","      <td>0.898810</td>\n","      <td>0.881548</td>\n","      <td>0.872321</td>\n","      <td>0.022138</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>32.319166</td>\n","      <td>1.114590</td>\n","      <td>3.331050</td>\n","      <td>0.221956</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>8</td>\n","      <td>{'lstm2': 16, 'lstm1': 4, 'dense1': 8}</td>\n","      <td>0.712500</td>\n","      <td>0.739286</td>\n","      <td>0.803571</td>\n","      <td>0.721429</td>\n","      <td>0.744196</td>\n","      <td>0.035611</td>\n","      <td>17</td>\n","      <td>0.817857</td>\n","      <td>0.858333</td>\n","      <td>0.897619</td>\n","      <td>0.870238</td>\n","      <td>0.861012</td>\n","      <td>0.028700</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>31.575402</td>\n","      <td>1.122663</td>\n","      <td>2.918107</td>\n","      <td>0.360206</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>32</td>\n","      <td>{'lstm2': 16, 'lstm1': 8, 'dense1': 32}</td>\n","      <td>0.758929</td>\n","      <td>0.821429</td>\n","      <td>0.783929</td>\n","      <td>0.719643</td>\n","      <td>0.770982</td>\n","      <td>0.037059</td>\n","      <td>3</td>\n","      <td>0.907738</td>\n","      <td>0.916071</td>\n","      <td>0.875595</td>\n","      <td>0.908929</td>\n","      <td>0.902083</td>\n","      <td>0.015621</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>31.673986</td>\n","      <td>0.370218</td>\n","      <td>3.039603</td>\n","      <td>0.290752</td>\n","      <td>16</td>\n","      <td>8</td>\n","      <td>4</td>\n","      <td>{'lstm2': 16, 'lstm1': 8, 'dense1': 4}</td>\n","      <td>0.735714</td>\n","      <td>0.792857</td>\n","      <td>0.741071</td>\n","      <td>0.726786</td>\n","      <td>0.749107</td>\n","      <td>0.025769</td>\n","      <td>14</td>\n","      <td>0.901786</td>\n","      <td>0.885714</td>\n","      <td>0.799405</td>\n","      <td>0.881548</td>\n","      <td>0.867113</td>\n","      <td>0.039815</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>30.005222</td>\n","      <td>1.278782</td>\n","      <td>2.821486</td>\n","      <td>0.321255</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>32</td>\n","      <td>{'lstm2': 16, 'lstm1': 4, 'dense1': 32}</td>\n","      <td>0.758929</td>\n","      <td>0.800000</td>\n","      <td>0.825000</td>\n","      <td>0.735714</td>\n","      <td>0.779911</td>\n","      <td>0.034750</td>\n","      <td>1</td>\n","      <td>0.897619</td>\n","      <td>0.838690</td>\n","      <td>0.847024</td>\n","      <td>0.908333</td>\n","      <td>0.872917</td>\n","      <td>0.030440</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>36.494431</td>\n","      <td>0.870843</td>\n","      <td>3.209851</td>\n","      <td>0.378902</td>\n","      <td>32</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>{'lstm2': 32, 'lstm1': 16, 'dense1': 16}</td>\n","      <td>0.757143</td>\n","      <td>0.782143</td>\n","      <td>0.789286</td>\n","      <td>0.732143</td>\n","      <td>0.765179</td>\n","      <td>0.022499</td>\n","      <td>6</td>\n","      <td>0.908929</td>\n","      <td>0.861310</td>\n","      <td>0.867262</td>\n","      <td>0.907738</td>\n","      <td>0.886310</td>\n","      <td>0.022128</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>32.873923</td>\n","      <td>1.236578</td>\n","      <td>2.787471</td>\n","      <td>0.504022</td>\n","      <td>16</td>\n","      <td>16</td>\n","      <td>4</td>\n","      <td>{'lstm2': 16, 'lstm1': 16, 'dense1': 4}</td>\n","      <td>0.767857</td>\n","      <td>0.814286</td>\n","      <td>0.742857</td>\n","      <td>0.721429</td>\n","      <td>0.761607</td>\n","      <td>0.034569</td>\n","      <td>8</td>\n","      <td>0.870833</td>\n","      <td>0.878571</td>\n","      <td>0.813690</td>\n","      <td>0.905952</td>\n","      <td>0.867262</td>\n","      <td>0.033569</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>42.126617</td>\n","      <td>0.655695</td>\n","      <td>3.211505</td>\n","      <td>0.301016</td>\n","      <td>32</td>\n","      <td>32</td>\n","      <td>4</td>\n","      <td>{'lstm2': 32, 'lstm1': 32, 'dense1': 4}</td>\n","      <td>0.771429</td>\n","      <td>0.792857</td>\n","      <td>0.757143</td>\n","      <td>0.741071</td>\n","      <td>0.765625</td>\n","      <td>0.019040</td>\n","      <td>5</td>\n","      <td>0.927381</td>\n","      <td>0.883333</td>\n","      <td>0.840476</td>\n","      <td>0.891071</td>\n","      <td>0.885565</td>\n","      <td>0.030890</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>30.650135</td>\n","      <td>0.948299</td>\n","      <td>2.290646</td>\n","      <td>0.551905</td>\n","      <td>8</td>\n","      <td>16</td>\n","      <td>32</td>\n","      <td>{'lstm2': 8, 'lstm1': 16, 'dense1': 32}</td>\n","      <td>0.780357</td>\n","      <td>0.805357</td>\n","      <td>0.744643</td>\n","      <td>0.730357</td>\n","      <td>0.765179</td>\n","      <td>0.029491</td>\n","      <td>6</td>\n","      <td>0.910714</td>\n","      <td>0.852381</td>\n","      <td>0.896429</td>\n","      <td>0.882143</td>\n","      <td>0.885417</td>\n","      <td>0.021583</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    mean_fit_time  std_fit_time  ...  mean_train_score  std_train_score\n","0       35.715215      0.280475  ...          0.872024         0.021350\n","1       30.617582      0.816938  ...          0.882440         0.008794\n","2       35.943490      0.469996  ...          0.854911         0.022788\n","3       28.740405      1.097446  ...          0.853125         0.049554\n","4       31.760548      0.354100  ...          0.868006         0.031130\n","5       35.209018      0.957863  ...          0.895238         0.018968\n","6       28.662930      0.571588  ...          0.794048         0.043997\n","7       28.467727      0.742300  ...          0.876637         0.033814\n","8       31.745901      0.539628  ...          0.853720         0.035441\n","9       32.825748      1.294722  ...          0.888839         0.010651\n","10      33.350198      0.293724  ...          0.866071         0.017164\n","11      30.854425      1.467581  ...          0.872321         0.022138\n","12      32.319166      1.114590  ...          0.861012         0.028700\n","13      31.575402      1.122663  ...          0.902083         0.015621\n","14      31.673986      0.370218  ...          0.867113         0.039815\n","15      30.005222      1.278782  ...          0.872917         0.030440\n","16      36.494431      0.870843  ...          0.886310         0.022128\n","17      32.873923      1.236578  ...          0.867262         0.033569\n","18      42.126617      0.655695  ...          0.885565         0.030890\n","19      30.650135      0.948299  ...          0.885417         0.021583\n","\n","[20 rows x 21 columns]"]},"metadata":{"tags":[]},"execution_count":74}]},{"cell_type":"code","metadata":{"id":"pQRkWpat-gZ3","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":187},"executionInfo":{"status":"ok","timestamp":1593023714093,"user_tz":-120,"elapsed":1561945,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"e9b4278b-f0dd-446e-f8a7-94f7e5ca11a5"},"source":["print(grid_result.best_score_)\n","print(grid_result.best_params_)\n","\n","# test_accuracy = grid.score(x_test_pad, test_target)\n","# print(test_accuracy)\n","print(grid_result)\n","\n","\n","# train_accuracy = grid.score(x_train_pad, train_target)\n","# print(train_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0.7799107134342194\n","{'lstm2': 16, 'lstm1': 4, 'dense1': 32}\n","RandomizedSearchCV(cv=4, error_score=nan,\n","                   estimator=<keras.wrappers.scikit_learn.KerasClassifier object at 0x7fc5d59db6a0>,\n","                   iid='deprecated', n_iter=20, n_jobs=-1,\n","                   param_distributions={'dense1': [4, 8, 16, 32],\n","                                        'lstm1': [4, 8, 16, 32],\n","                                        'lstm2': [4, 8, 16, 32]},\n","                   pre_dispatch='2*n_jobs', random_state=None, refit=True,\n","                   return_train_score=True, scoring=None, verbose=1)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"emfAjjqFh-yp","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1593023715640,"user_tz":-120,"elapsed":1563470,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"fa9d042a-f1f0-4828-f48b-dd6739664f7e"},"source":["threshold = 0.5\n","predicted = grid.predict(x_train_pad)\n","\n","predicted = np.where(predicted > threshold, 1,0)\n","\n","\n","predicted  = np.reshape(predicted, len(predicted))\n","\n","\n","eval_predicted = grid.predict(x_test_pad)\n","\n","eval_predicted = np.where(eval_predicted > threshold, 1,0)\n","\n","eval_predicted  = np.reshape(eval_predicted, len(eval_predicted))\n","\n","# train acc\n","\n","no_predictions = len(predicted)\n","print(no_predictions)\n","\n","right = np.sum(predicted == train_target)\n","\n","training_accuracy = right/ no_predictions\n","print(\"Training Accuracy: \", training_accuracy)\n","\n","\n","# test acc\n","\n","no_predictions_eval = len(eval_predicted)\n","print(no_predictions_eval)\n","\n","right_eval = np.sum(eval_predicted == test_target)\n","\n","test_accuracy = right_eval/ no_predictions_eval\n","print(\"Test Accuracy: \", test_accuracy)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2240\n","Training Accuracy:  0.9254464285714286\n","720\n","Test Accuracy:  0.7222222222222222\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"n6oaJFs1imnH","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":158},"executionInfo":{"status":"ok","timestamp":1593023715644,"user_tz":-120,"elapsed":1563448,"user":{"displayName":"Clyde Tran","photoUrl":"","userId":"01612062056156838085"}},"outputId":"7e97a8bd-e5ff-4040-e338-681d99d7493f"},"source":["from sklearn.linear_model import LogisticRegression\n","import sklearn.metrics as sk\n","\n","\n","precision = sk.precision_score(train_target, predicted)\n","print(\"Training Precision: \", precision)\n","recall = sk.recall_score(train_target, predicted)\n","print(\"Training recall: \", recall)\n","roc_auc = sk.roc_auc_score(train_target, predicted)\n","print(\"Training roc_auc: \", roc_auc)\n","f1 = sk.f1_score(train_target, predicted)\n","print(\"Training f1: \", f1)\n","\n","\n","precision = sk.precision_score(test_target, eval_predicted)\n","print(\"Eval Precision: \", precision)\n","recall = sk.recall_score(test_target, eval_predicted)\n","print(\"Eval recall: \", recall)\n","roc_auc = sk.roc_auc_score(test_target, eval_predicted)\n","print(\"Eval roc_auc: \", roc_auc)\n","f1 = sk.f1_score(test_target, eval_predicted)\n","print(\"Eval f1: \", f1)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Training Precision:  0.9022265246853823\n","Training recall:  0.9338677354709419\n","Training roc_auc:  0.9262736422926368\n","Training f1:  0.9177744953225012\n","Eval Precision:  0.6048632218844985\n","Eval recall:  0.7397769516728625\n","Eval roc_auc:  0.7257643073220188\n","Eval f1:  0.6655518394648829\n"],"name":"stdout"}]}]}